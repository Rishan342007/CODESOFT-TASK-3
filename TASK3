# ----------------------------------------------------
# ğŸ¯ Task 3: Customer Churn Prediction App
# ğŸ‘¨â€ğŸ’» Intern: Rishan . N
# ğŸ« Rajalakshmi Institute of Technology
# ğŸ¢ Internship at: CodSoft
# ----------------------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ğŸ¯ Simulated Customer Churn Dataset
np.random.seed(42)
n_samples = 1000
data = {
    'age': np.random.randint(18, 70, size=n_samples),
    'subscription_length': np.random.randint(1, 36, size=n_samples),
    'monthly_usage_hours': np.random.normal(20, 5, size=n_samples),
    'support_tickets': np.random.poisson(1.5, size=n_samples),
    'gender': np.random.choice([0, 1], size=n_samples),  # 0 = Female, 1 = Male
    'churn': np.random.choice([0, 1], size=n_samples, p=[0.85, 0.15])  # 15% churn rate
}
df = pd.DataFrame(data)

# ğŸ“Š Pie Chart â€“ Churn Distribution (No emoji in plot)
churn_counts = df['churn'].value_counts()
plt.figure(figsize=(5, 5))
plt.pie(churn_counts, labels=["Stayed (0)", "Churned (1)"],
        colors=["mediumseagreen", "tomato"], autopct='%1.1f%%',
        shadow=True, startangle=140, explode=(0, 0.1))
plt.title("Churn Distribution")
plt.tight_layout()
plt.show()

# âš™ï¸ Preprocessing
X = df.drop('churn', axis=1)
y = df['churn']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ”€ Split Dataset
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, stratify=y, random_state=42
)

# ğŸ” Train Models
log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train, y_train)
log_pred = log_model.predict(X_test)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

gb_model = GradientBoostingClassifier()
gb_model.fit(X_train, y_train)
gb_pred = gb_model.predict(X_test)

# ğŸ“ˆ Evaluate Models (No warning)
log_acc = round(accuracy_score(y_test, log_pred) * 100, 2)
rf_acc = round(accuracy_score(y_test, rf_pred) * 100, 2)
gb_acc = round(accuracy_score(y_test, gb_pred) * 100, 2)

log_report = classification_report(y_test, log_pred, zero_division=0)
rf_report = classification_report(y_test, rf_pred, zero_division=0)
gb_report = classification_report(y_test, gb_pred, zero_division=0)

# ğŸ”³ Confusion Matrices
plt.figure(figsize=(15, 4))
plt.subplot(1, 3, 1)
sns.heatmap(confusion_matrix(y_test, log_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Logistic Regression")

plt.subplot(1, 3, 2)
sns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt='d', cmap='Greens')
plt.title("Random Forest")

plt.subplot(1, 3, 3)
sns.heatmap(confusion_matrix(y_test, gb_pred), annot=True, fmt='d', cmap='Oranges')
plt.title("Gradient Boosting")

plt.tight_layout()
plt.show()

# âœ… Final Output
print("----------------------------------------------------")
print("ğŸ‰ Task 3 Completed: Customer Churn Prediction")
print("ğŸ‘¨â€ğŸ’» Submitted by: Rishan . N")
print("ğŸ« Rajalakshmi Institute of Technology")
print("ğŸ¢ Internship at: CodSoft")
print("----------------------------------------------------\n")

print(f"ğŸ“Š Logistic Regression Accuracy: {log_acc}%\n{log_report}")
print(f"ğŸŒ² Random Forest Accuracy: {rf_acc}%\n{rf_report}")
print(f"âš¡ Gradient Boosting Accuracy: {gb_acc}%\n{gb_report}")

print("----------------------------------------------------")
print("ğŸ‘¨â€ğŸ’» Submitted by: Rishan . N")
print("ğŸ« Rajalakshmi Institute of Technology")
print("ğŸ¢ Internship at: CodSoft")
print("----------------------------------------------------")
